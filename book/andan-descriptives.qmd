# Описательные статистики {#andan-descriptives}
::: {.lab-chapter .lab-junior}
:::

```{r andan-desc-pkgs, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
theme_set(theme_bw())
```

{{< include _symbols.qmd >}}

## Виды статистики {#andan-descriptives-kinds-of-stats}
::: {.lab-chapter .lab-junior}
:::

Вообще статистика [как набор методов и инструментов] делится на два вида --- описательная статистика и статистика вывода.

- **Описательная статистика (descriptive statistics[^desc-stats-1])** занимается обработкой статистических данных, их наглядным представлением, и собственно описанием через некоторые характеристики.
  - Эти характеристики, количественно описывающие особенности имеющихся данных, называются **описательными статистиками (descriptive statistics[^desc-stats-2])**.
  - *Задача описательной статистики* --- ёмко описать имеющиеся данные и составить на основе этих описаний общее представление о них, а также обнаружить особенности, которые могут повлиять на дальнейший анализ.
- **Статистика вывода (inferential statistics)** занимается поиском ответов на содержательные вопросы, которые мы задаем данным в ходе их анализа в рамках научных и практических исследований.
  - Состоит из двух компонентов --- *тестирования статистических гипотез* и *статистических методов*.

[^desc-stats-1]: Mass (uncountable) noun
[^desc-stats-2]: Countable noun, plural in this case

::: {.callout-note title="Замечание о машинном обучении"}

В названии книги упомянуто «машинное обучение». Иногда его причисляют к статистике, иногда рассматривают отдельно. На самом же деле, статистические методы лежат где-то между статистикой вывода и машинным обучением.

Почему?

Дело в том, что на статистические методы можно смотреть по-разному.

- Если нашей задачей является поиск ответов на **исследовательские** вопросы о закономерностях, о связи каких-либо факторов или влиянии переменных друг на друга, то мы будем смотреть на статистические модели с точки зрения статистики вывода. Это позволит нам находить ответы на интересующие нас вопросы --- причем не важно, говорим мы о научных исследованиях или об исследованиях в индустрии.
- Если перед нами стоит задача хорошо **предсказывать** одни переменные на основании значений других --- например, выдавать рекомендации на Яндекс.Музыке или в Яндекс.Лавке --- то мы будем смотреть на те же статистические модели с точки зрения машинного обучения.

То есть, модели в анализе данных и машинном обучении одни и те же, но то, какую модель мы назовем хорошей и как мы эту «хорошесть» определим, будет отличаться в зависимости от задачи --- *исследовательская* или *предиктивная* --- которая перед нами стоит.

:::



## Меры центральной тенденции {#andan-descriptives-central-tendency}
::: {.lab-chapter .lab-junior}
:::

Итак, мы хотим описать наши данные. Точнее, распределения переменных, которые у нас в данных есть. Хотим сделать это просто и ёмко. Насколько просто и ёмко? Ну, допустим максимально — одним числом. Для этого неплохо подойдет значение переменной, которое лежит *в центре* распределения.

Как мы будем искать, что там в центре распределения? Зависит от [шкалы](), в которой измерена конкретная переменная (@tbl-scales-cental-tendencies).

|    **Шкала**   |        **Мера центральной тенденции**        |
|:---------------|:---------------------------------------------|
| _Номинальная_  | Мода                                         |
| _Порядковая_   | Медиана                                      |
| _Интервальная_ | Среднее арифметическое                       |
| _Абсолютная_   | Среднее арифметическое, геометрическое и др. |

: Шкалы и меры центральной тенденции {#tbl-scales-cental-tendencies tbl-colwidths="[25,75]"}

Однако есть некоторые нюансы.


### Мода {#andan-descriptives-mode}
::: {.lab-chapter .lab-junior}
:::

Самый простой вариант найти центральную тенденцию --- это определить наиболее часто встречающееся значение переменной. Это значение называется *модой (mode)*.

::: {#def-mode-discrete}
**Мода** [дискретной переменной] --- наиболее часто встречающееся значение данной переменной.
:::

Например, у нас есть следующий ряд наблюдений по какой-то переменной:

$$
\begin{bmatrix}
1 & 3 & 4 & 6 & 3 & 2 & 3 & 3 & 2 & 4 & 1
\end{bmatrix}
$$

Если мы посчитаем, сколько раз встретилась каждое значение переменной и составим таблицу частот, то получим следующее:

$$
\begin{matrix}
\text{Значение} & 1 & 2 & 3 & 4 & 6 \\
\text{Частота}  & 2 & 2 & 4 & 2 & 1
\end{matrix}
$$

Очевидно, что $3$ встречается чаще других значений --- это и есть мода.

Понятно, что если на нашей шкале нет чисел, а есть текстовые лейблы, это ничего не меняет. Пусть у нас есть переменная с кодами аэропортов:

$$
\begin{bmatrix}
\text{DME} & \text{LED} & \text{IST} & \text{AER} & \text{IST} &\text{SVO} & \text{LED} & \text{VKO} & \text{LED} & \text{IST} & \text{IST} & \text{VKO} & \text{AER} & \text{DME}
\end{bmatrix}
$$

$$
\begin{matrix}
\text{Значение} & \text{DME} & \text{LED} & \text{IST} & \text{AER} & \text{SVO} & \text{VKO}\\
\text{Частота}  & 2 & 3 & 4 & 2 & 1 & 2
\end{matrix}
$$

Мода --- $\text{IST}$ (Международный аэропорт Стамбула, İstanbul Havalimanı).

Так мы действуем в случае с эмпирическим распределением. Если нам известна [функция вероятности переменной (probability mass function, PMF)](), то мы можем определить моду, основываясь на ней:

::: {#def-mode-discrete-pmf}
**Мода** [дискретной переменной] --- это значение переменной, при котором её функция вероятности принимает своё максимальное значение.
:::

$$
\text{mode}(X) = \arg \max(\text{PMF}(X)) = \arg \max_{x_i}(\prob (X = x_i)),
$$ {#eq-mode-pmf}

где $X$ --- дискретная случайная величина, $x_i$ --- значение этой случайной величины.

```{r mode-pmf, echo=FALSE}
#| label: fig-mode-pmf
#| fig-cap: "Определение моды с помощью функции вероятности"
tibble(x = 1:10,
       y = c(.01, .03, .07, .1, .1, .15, .2, .1, .09, .15)) |> 
  ggplot(aes(x, y)) +
  annotate(geom = "point", x = 7, y = 0.2, size = 7, shape = 21, color = "darkred", fill = "red", alpha = .5) +
  geom_point() +
  geom_vline(xintercept = 7, color = "darkred", linetype = "dashed") +
  annotate(geom = "text", label = "это максимум функции", 
           x = 8.5, y = 0.2, color = "darkred") +
  annotate(geom = "text", label = "это мода", 
           x = 7, y = 0, color = "darkred") +
  scale_x_continuous(breaks = 1:10) +
  labs(x = "Value", y = "Probability")
```

Окей, мы видим, что *мода отлично считается на дискретных переменных*. А как же быть с непрерывными?

[Напомним себе](), что вероятность того, что непрерывная случайная величина примет своё конкретное значение, равна нулю. Из этого следует, что все значения непрерывной случайное величины уникальны --- каждое повторяется только один раз. Получается, что строить частотную таблицу бессмысленно...

По этой причине **для непрерывных переменных моду не считают**.


#### Мода для непрерывной переменной {#andan-descriptives-mode-contunious}
::: {.lab-chapter .lab-middle}
:::

Да, это так. Действительно, посчитать моду для непрерывной переменной способом, аналогичным тому, что мы увидели выше, не получится. Однако математиков это не остановило.

Если мы посмотрим на [график плотности вероятности]() (probability density function, PDF), который является аналогом PMF для дискретных переменных, мы увидим, что какие-то значения встречаются чаще, а какие-то реже. Что в общем-то логично. Напомним себе, [как это выглядит](), например, для любимого [стандартного] [нормального распределения]():

```{r mode-continuous-data, echo=FALSE}
mode_cont_data <- tibble(x = seq(-4, 4, by = .01), y = dnorm(x))
mode_high_freq <- mode_cont_data |> filter(x > -.5 & x < .5)
mode_low_freq <- mode_cont_data |> filter(x > -2.5 & x < -1.5)
```

```{r mode-continuous-freqs, echo=FALSE}
#| label: fig-continuous-freqs
#| fig-cap: "Частоты интервалов значений непрерывной случайной величины на функции плотности распределения"
ggplot(mode_cont_data,
       aes(x, y)) +
  geom_line() +
  geom_polygon(data = tibble(y = c(0, 0), x = c(.5, -.5)) |> 
                 bind_rows(mode_high_freq),
               fill = "seagreen", alpha = .5) +
  geom_polygon(data = tibble(y = c(0, 0), x = c(-1.5, -2.5)) |>
                 bind_rows(mode_low_freq),
               fill = "royalblue", alpha = .5) +
  annotate(geom = "text", label = "эти значения встречаются часто",
           x = 0, y = .2, angle = 90, color = "darkgreen") +
  annotate(geom = "text", label = "эти значения\nвстречаются реже",
           x = -2.2, y = .15, angle = 90, color = "darkblue") +
  labs(x = "Value", y = "Density")
```

То есть, самые часто встречающиеся значения --- это **пик распределения**. Там и должна быть мода. Визуально это выглядит достаточно справедливо.

Математики так и решили:

::: {#def-mode-continuous}
**Мода** [непрерывной переменной] --- это значение переменной, при котором её функция плотности вероятности достигает локального[^local-max-mode] максимума.
:::

[^local-max-mode]: Здесь в примере локальный максимум функции плотности вероятности на интервале $(-4, \, 4)$ совпадает с глобальным максимумом --- мы об этом знаем, потому что форма распределения нам известна. В случае эмпрического распределения корректнее говорить именно о локальном максимуме, так как глобальный максимум нам не доступен ввиду того, что мы работаем с выборкой.

$$
\text{mode}(X) = \arg \max(\text{PDF}(X)) = \arg \max_{x \in S}f(x),
$$ {#eq-mode-pdf}

гдe $X$ --- непрерывная случайная величина, $x$ --- значение этой случайной величины, $S$ --- имеющаяся выборка значений переменной.

```{r mode-continuous-mode, echo=FALSE}
#| label: fig-continuous-mode
#| fig-cap: "Положение моды на функции плотности [стандартного] нормального распределения"
ggplot(mode_cont_data,
       aes(x, y)) +
  geom_line() +
  geom_polygon(data = tibble(y = c(0, 0), x = c(.5, -.5)) |> 
                 bind_rows(mode_high_freq),
               fill = "seagreen", alpha = .5) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "darkgreen") +
  geom_point(aes(x = 0, y = .4), color = "darkgreen", size = 2) +
  annotate(geom = "text", label = "мода тут",
           x = 0, y = 0, color = "darkgreen") +
  annotate(geom = "text", label = "локальный максимум тут",
           x = 1.5, y = 0.4, color = "darkgreen") +
  labs(x = "Value", y = "Density")
```

Хотя моду для непрерывной переменной вычислить можно, обычно этого не делают, так как достаточно других мер центральной тенденции для описания распределения.

***

::: {.callout-warning title="Take-home: мода"}
- мода --- это значение переменной, которое встречается в выборке чаще всего
- на практике она рассчитывается через построение частотной таблицы
- используется с дискретными (номинальными и порядковыми) переменными
- для непрерывных переменных её рассчитать можно, но обычного этого не делают
:::



### Унимодальные и полимодальные распределения {#andan-descriptives-unimodal-bimodal}
::: {.lab-chapter .lab-junior}
:::

Нормальное распределение, как и ряд других --- биномиальное, отрицательное биномиальное, пуассоновское --- относятся к *унимодальным*. Такие распределения имеют только *одну моду*.

ПРОДОЛЖИТЬ




### Медиана {#andan-descriptives-median}
::: {.lab-chapter .lab-junior}
:::

### Среднее {#andan-descriptives-mean}
::: {.lab-chapter .lab-junior}
:::

#### Арифметическое среднее {#andan-descriptives-arithmetic-mean}
::: {.lab-chapter .lab-junior}
:::

#### Усеченное среднее {#andan-descriptives-trimmed-mean}
::: {.lab-chapter .lab-junior}
:::

#### Геометрическое среднее {#andan-descriptives-geometric-mean}
::: {.lab-chapter .lab-middle}
:::

#### Квардатичное среднее {#andan-descriptives-quandratic-mean}
::: {.lab-chapter .lab-middle}
:::

#### Гармоническое среднее {#andan-descriptives-harmonic-mean}
::: {.lab-chapter .lab-middle}
:::

#### Взвешенное среднее {#andan-descriptives-weighted-mean}
::: {.lab-chapter .lab-junior}
:::

### Среднее vs медиана {#andan-descriptives-mean-vs-median}
::: {.lab-chapter .lab-junior}
:::


## Меры разброса {#andan-descriptives-variability}
::: {.lab-chapter .lab-junior}
:::

### Минимум, максимум, размах {#andan-descriptives-range}
::: {.lab-chapter .lab-junior}
:::

### Среднее абсолютное отклонение {#andan-descriptives-average-absolute-deviation}
::: {.lab-chapter .lab-middle}
:::

#### Среднее абсолютное отклонение от среднего {#andan-descriptives-mean-absolute-deviation-around-the-mean}
::: {.lab-chapter .lab-middle}
:::

#### Среднее абсолютное отклонение от медианы {#andan-descriptives-mean-absolute-deviation-around-the-median}
::: {.lab-chapter .lab-middle}
:::

#### Медианное абсолютное отклонение {#andan-descriptives-median-absolute-deviation}
::: {.lab-chapter .lab-middle}
:::


### Дисперсия {#andan-descriptives-variance}
::: {.lab-chapter .lab-junior}
:::

#### Дисперсия генеральной совокупности {#andan-descriptives-population-variance}
::: {.lab-chapter .lab-junior}
:::

#### Дисперсия выборки {#andan-descriptives-sample-variance}
::: {.lab-chapter .lab-junior}
:::

### Стандартное отклонение {#andan-descriptives-standard-deviation}
::: {.lab-chapter .lab-junior}
:::




## Асимметрия {#andan-descriptives-skewness}
::: {.lab-chapter .lab-junior}
:::

## Эксцесс {#andan-descriptives-kurtosis}
::: {.lab-chapter .lab-junior}
:::


## Итоги {#andan-descriptives-final}

