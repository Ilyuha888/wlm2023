# Тестирование статистических гипотез {#stats-testing}

В ходе статистического анализа мы, главным образом, заняты тем, что тестируем статистические гипотезы. Ведь на какого рода вопросы мы отвечаем с помощью анализа?

- Различаются ли группы между собой?
- Значимо ли влияние какого-либо фактора? → Различаются ли группы между собой?
- Хороша ли та модель, которую мы построили? → Отличается ли она от нулевой модели?

И так далее. Так или иначе, всё сводится в тому, что мы ищем какие-то различия. Но силу того, что у нас неопределённость и вариация в данных, мы просто так «в лоб» сказать о различиях по оценкам параметров не можем. Приходится тестировать статистические гипотезы.

## Нулевая и альтернативная гипотезы {#stats-testing-hyotheses}

Еще раз тезисно [вспомним о гипотезах](#stats-hypotheses) в целом:

- **Гипотеза** ($H$) --- это предположение, которое подлежит проверке на основе результатов наблюдений.
- Гипотезы бывают:
    - **теоретические** --- про конструкты
    - **эмпирические** --- про переменные
    - **статистические** --- про параметры [генеральной совокупности] и данные

Статистические гипотезы бывают простыми и сложными:

- **Простая гипотеза** --- это такое предположение, которое включает в себя какое-либо однозначно определеяемое утверждение. Например, истинная величина параметра соответствует некоторому строго заданному значению: $H : \theta = \theta_0$. Другой вариант --- две генеральные совокупности имеют одно и то же значение одной и той же характеристики: $H : \theta_1 = \theta_2$.
- **Сложная гипотеза** предполагает множественность вариантов для параметра, которые укладываются в рамки проверяемого предположения. Например, $H : \theta > \theta_0$ или $H : \theta_1 \neq \theta_2$.

В рамках самого хода тестирования гипотез существует **проверяемая (нулевая) гипотеза** ($H_0$). Её обычно стараются предельно упростить, поэтому она формулируется как простая гипотеза. В противовес ей выдвигается **альтернативная гипотеза** ($H_1$), которая будет иметь вид сложной гипотезы.

Для проверки гипотезы необходимы две вещи:

- результаты наблюдений и
- критерий.

Результаты наблюдений, полученные на выборке, сами по себе, как правило, не используются. Однако на их основе рассчитываются выборочные статистики (показатели), которые непосредственно участвуют в проверке гипотезы.


## Подходы к тестированию статистических гипотез {#stats-testing-approaches}

### Фреквентистский подход {#stats-testing-nhst}

### Байесовский подход {#stats-testing-bayes}

## Возможные результаты проверки гипотез {#stats-testing-results}

В результате проверки статистических гипотез могут возникнуть четыре ситуации.

Мы изучаем в исследовании какую-либо закономерность, которая в реальном мире может существовать, а может и не существовать. В силу неопределённости и вариативности наших данных мы может либо обнаружить интересующую нас закономерность, либо не обнаружить.

В качестве нулевой гипотезы мы выдвигаем предположение о том, что закономерность отсутствует --- так мы упрощаем нашу нулевую гипотезу. Пусть $H_0$ обозначает, что предположение, которое мы проверяем справедливо, а $H_1$ --- не справедливо. На основании данных мы можем либо не отклонить наше предположение ($\hat H_0$), либо отклонить ($\hat H_1$).

Тогда имеем следующую ситуацию:

ТАБЛИЦА

- **Ошибка I рода** возникает, когда в генеральной совокупности _искомой закономерности нет_, но мы в силу случайных флуктуаций в данных _её нашли_.
- **Ошибка II рода** возникает, когда в генеральной совокупности _искомая закономерность есть_, но мы в силу каких-либо причин её _не нашли_.

Ошибки --- это нехорошо, они нас не устраивают. Надо каким-то образом их контролировать.

- **Ошибка I рода** контролируется достаточно просто. Так как мы _нашли_ закономерность, которую искали, мы можем посчитать вероятность, с которой потенциально ошиблись. А собственно контролировать ошибку мы будем с помощью **уровня значимости** $\alpha$, который _выбирается до начала процедуры тестирования гипотезы_. Он и задает вероятность, с который мы позволяем себе ошибиться — отклонить нулевую гипотезу, при условии, что она верна.
- **Ошибку II рода** контролировать сложнее, так как мы _не нашли_ закономерность, которую искали. Нам нужна какая-то метрика, которая позволит сказать, что мы сделали всё возможное для того, чтобы обнаружить искомую закономерность. Вероятность ошибки II рода обозначается $\beta$ --- тогда вероятность того, что мы не совершили ошибку II рода будет $1 - \beta$. Эта величина называется [**статистической мощностью**](#stats-testing-effect-size), и она связана с [_размером эффекта_](#stats-testing-effect-size) и _объемом выборки_. Статистическую мощность можно рассчитать как до проведения статистического анализа  для расчета требуемого объема выборки --- так и после --- для определения достигнутой статистической мощности.





### Асимметрия статистического вывода {#stats-testing-asymmetry}

### Связь ошибки первого и второга рода {#stats-testing-errors-connection}


## Агоритм тестирования статистических гипотез {#stats-testing-algorithm}


## Проблема множественных сравнений {#stats-testing-multiple-comparisons}

## Проблема количества статистических тестов {#stats-testing-multiple-testing}


## Размер эффекта {#stats-testing-effect-size}


## Статистическая мощность {#stats-testing-power}

::: {.callout-note title="Статистическая мощность Post hoc"}
НАПИСАТЬ

кажется, нет, так как эффект уже нашли
:::
