# L6 // Оценивание параметров в практике статистического анализа. Тестирование статистических гипотез

{{< include ../book/_symbols.qmd >}}

```{r opts, echo=FALSE, eval=TRUE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE)
```

```{r pkgs}
library(tidyverse)
theme_set(theme_bw())
```


## Оценивание параметров

Напомним себе весьма малоприятную ситуацию, в которой мы находимся, когда решаем провести некоторое исследование. Мы заинтересованы в изучении **генеральной совокупности**. Объекты интересующей нас генеральной совокупности обладают определенными **признаками**, которые мы, собственно, хотели бы изучать. Признаки _количественно выражены_ в определенных **показателях**.

Признаки могут быть очень разными и измеряться могут с помощью разных показателей. Независимо от того, как измеряется признак, генеральная совокупность характеризуется _параметром_.

**Параметр** ($\theta$) --- относительно постоянная [от одной совокупности к другой] величина, харакретизующая генеральную совокупность по некоторому показателю.

Проблема в том, что **величина параметра, который мы изучаем, неизвестна**. И никогда не будет известна. Потому что

- мы никогда не можем изучать всю генеральную совокупность, так как она содержит слишком много объектов
- наши измерения всегда содержат ошибку, из-за чего мы ничего не можем измерить точно

Нам остаётся работать только с *выборочной совокупность (выборкой)* и опираться на статистические данные, которые мы собираем на ней. Измеряя что-либо на выборке, мы получаем **выборочную характеристику, или оценку** ($\hat \theta$) --- эмпирический (измеримый) аналог параметра.

Выборка извлекается из генеральной совокупности случайным образом, поэтому что там именно --- с точки зрения данных --- в нашей выборке будет нам также неизвестно. Отсюда происходят два ключевых свойства статистических данных --- *неопредлённость* и *вариативность*.

**Неопределённость** нам говорит о том, что мы не знаем, что именно мы получим в результате наших измерений для конкретной выборки. В том числе потому, что мы работаем на просторах случайных величин.

**Вариативность** означает, что наши данные будут различатся ещё и от респондента к респонденту. И между выборками тоже. Здесь и ошибка измерения, и различные смешения и ещё куча всего.

В итоге что мы имеем: так как нам не доступны *истинные* значения параметров, придётся использовать *оценки* этих параметров. Возникает вопрос: как нам получить эти оценки? и какими свойствами они должны обладать, чтобы хорошо отражать параметры генеральной совокупности?



### Точечные оценки
::: {.lab-chapter .lab-junior}
:::

Пусть у нас есть некоторый параметр генеральной совокупности $\theta$. Его аналогом на выборочной совокупности является его *точечная оценка* $\hat \theta$. Точечная она, потому что представляет собой некоторое одно число. Таким образом, это наиболее компактный способ составить представление о значении параметра. По своей сути она, на самом деле, является функцией --- по факту, случайной величиной ---- от результатов наблюдений:

$$
\hat \theta = \hat \theta (\vm x), \; \vm x = \pmatrix{ x_1 & x_2 & \dots & x_n}
$$

Это всё замечательно, но что это значит для нас как для практиков? Значение оценки зависит от наблюдений, поэтому на разных выборках мы будем получать разные значения оценки. Возьмем для примера такой параметр как _среднее значение_. Пусть мы изучаем интеллект --- это наш признак --- который мы измеряем как коэффициент IQ --- это наш показатель ($X$). Известно, что в генеральной совокупности этот признак распределен нормально с математическим ожиданием 100 и стандартным отклонением 15, то есть $X \thicksim \mathcal N(100, 225)$:

```{r}
ggplot() +
  geom_function(fun = dnorm, args = list(mean = 100, sd = 15)) +
  geom_vline(xintercept = 100,
             linetype = "dashed") +
  xlim(30, 170)
```

Тут нам, конечно, повезло, потому что мы знаем, как устроена шкала IQ[^iq_scale], поэтому мы знаем значение нашего параметра --- $\mu = 100$. В общем случае, конечно, значение параметра, как мы отмечали выше, неизвестно.

[^iq_scale]: Шкала IQ устроена так, что её среднее значение равно 100, а стандартное отклонение 15.

Теперь попробуем наизвлекать выборок человек по 50 и посчитать *оценки среднего (выборочные средние)* $\hat \mu$ на них:

```{r}
matrix(rnorm(50 * 12, 100, 15), ncol = 12) %>% 
  as_tibble() %>% 
  pivot_longer(cols = everything()) %>% 
  mutate(name = str_replace(name, "V", "sample ") %>% 
           factor(ordered = TRUE, levels = paste("sample", 1:12))) -> iq_sim
iq_sim %>% 
  ggplot(aes(value)) +
  geom_histogram(binwidth = 3, fill = 'gray50') +
  geom_vline(data = iq_sim %>% 
               summarise(mean = mean(value),
                         .by = name),
             aes(xintercept = mean)) +
  facet_wrap(~ name, ncol = 4, scales = "free_x") +
  labs(x = 'IQ',
       y = 'Count')
```

Наблюдаем, что иногда мы при подсчёте оценке параметра попадаем близко к истинному его значению, иногда промахиваемся. Собственно, как раз об этом *неопределённость и вариация*.


#### Метод моментов
::: {.lab-chapter .lab-junior}
:::

Чтобы получить точечные оценки параметров, используются разные методы. Метод зависит от того, какой параметр мы хотим оценить, а также с какой моделью мы сейчас работаем. Сейчас мы познакомимся с самым простым --- **методом моментов**.

Слово «момент» обычно вызывает странные ощущения --- какой момент? момент чего? что в этот момент случается? Тут надо отпустить привычное понимание слово «момент» как некоторого момента времени и принять тот факт, что «момент случайной величины» --- а именно о нём мы говорим --- это просто характеристика распределения случайной величины. То есть математическое ожидание --- это момент распределения случайной величины, дисперсия --- это момент распределения случайной величины.

В методе моментов есть три этапа:

1) устанавливается связь между оцениваемым параметром и моментом распределения случайной величины

$$
\quad \theta = \xi(\mu_k),
$$

где $\mu_k$ --- это момент случайной величины.

2) находятся выборочные моменты

$$
\hat \theta = \xi(\mu_k^*)
$$

3) истинный момент заменяется на выборочный --- получается оценка.

Для примера разберём всё тот же датасет с IQ. Мы знаем, что распределение баллов IQ подчинается [нормальному закону](#normal_distribution). Поэтому в качестве параметра «среднее значение коэффициента интеллекта» генеральной совокупности можно использовать математическое ожидание:

$$
\mu = \mathbb{E}X
$$

Выборочным аналогом математического ожидания является выборочное среднее:

$$
\hat \mu = \frac{1}{n} \sum_{i=1}^n x_i
$$

И это, собственно, всё. Если вы хотя бы раз анализировали данные, вы имплицитно пользовались этим знанием. Просто, скорее всего, не задумывались, что это так работает. :)


#### Метод максимального правдоподобия
::: {.lab-chapter .lab-middle}
:::

#### Bootstrap
::: {.lab-chapter .lab-middle}
:::

### Свойства точечных оценок
::: {.lab-chapter .lab-middle}
:::

Так как точечные оценки всё же оценки, мы можем и промахнуться мимо истинного среднего --- это мы наблюдали на гистограмме. Поэтому нам надо предъявить определённые требования к точечным оценкам. Их три: *несмещённость*, *состоятельность* и *эффективность*.

#### Несмещенность
::: {.lab-chapter .lab-middle}
:::

**Несмещённость** выражает следующую идею: когда мы рассчитываем выборочную оценку, мы должны как можно ближе попадать в истинное значение параметра.

$$
\forall n \; \mathbb{E} \hat \theta = \theta, \quad (\mathbb{E}\hat \theta - \theta) \rightarrow 0,
$$
где $n$ --- объём выборки, $(\mathbb{E}\hat \theta - \theta)$ --- смещение.

Слева представлено требование *несмещённости при любом объёме выборки*, а справа --- *ассимптотической несмещённости*.


#### Состоятельность
::: {.lab-chapter .lab-middle}
:::

Математически **состоятельность** определяется следующим образом:

$$
\lim_{n \rightarrow \infty} \mathrm{P}(|\hat \theta - \theta| < \varepsilon) = 1, \, \varepsilon > 0
$$

Содержательно эта запись нам говорит следующее, что при неограниченном росте мощности выборки наша оценка стремится к истинному значению параметра. Может быть, такая формулировка не совсем точна математически, но позволяет представить, что происходит. 


#### Эффективность
::: {.lab-chapter .lab-middle}
:::

Эффективность точечной оценки определяется достаточно просто. Так как оценка параметра --- это случайная величина, но у неё есть *дисперсия*. Чтобы оценка была **эффективна**, её дисперсия должна быть минимальной:

$$
\sigma^2_{\hat \theta} = \min
$$

Пример несмещённой, состоятельной и эффективной оценки --- это выборочное среднее для оценки математического ожидания нормально распределённой величины. Именно то, что мы и делали в примере применения метода моментов.



### Интервальные оценки
::: {.lab-chapter .lab-junior}
:::

Кроме самого значения оценки, необходимо определить качество этой оценки, иначе говоря --- её точность. Для этого используется такая величина как **надёжность**:

$$
\gamma = \mathrm{P}(\theta_\min < \theta < \theta_\max)
$$

Такая форма оценки называется **интервальной оценкой параметра**, так как мы указываем *интервал*, в котором находится истинное значение с определённой вероятностью.

Такая форма оценки даёт исчерпывающую информацию о параметре: мы знаем (1) интервал, в котором находится значение параметра генеральной совокупности, а также (2) надёжность, с которой выбранный интервал накрывает это значение.

Значение надежности $\gamma$ может быть выбрано произвольно, но обычно оно близко к единице. Однако необхожимо помнить, что чем выше надёжность, тем шире границы интервальной оценки.



#### Стандартная ошибка
::: {.lab-chapter .lab-junior}
:::


##### Почему $\se(X) = \frac{\sd(X)}{\sqrt{n}}$
::: {.lab-chapter .lab-senior}
:::

$$
\var (X + Y) = \var (X) + \var(Y) + 2 \cov (X, Y)
$$

$$
\var (aX) = a^2 \var (X)
$$

Так как наблюдения извлекаются из независимых одинаково распределенных величин (independent identically distributed, iid), то

$$
\cov (X_i, X_j) = 0, \sigma_{X_i} = \sigma_{X_j} = \sigma
$$

$$
\var \Big( \frac{1}{n} \sum X_i \Big) = \frac{1}{n^2} \sum \var(X_i) = \frac{1}{n^2} \sum \sigma^2 = \frac{n}{n^2} \sigma^2 = \frac{\sigma^2}{n}
$$

$$
\se_X = \sqrt{ \var \Big( \frac{1}{n} \sum X_i \Big)} = \sqrt{\frac{\sigma^2}{n}} = \frac{\sigma}{\sqrt{n}}
$$


#### Доверительный интервал
::: {.lab-chapter .lab-junior}
:::

Вариантом интервальной оценки является **доверительный интервал (confidence interval)**. Итак, ещё раз:

$$
\mathrm{P}(\theta_\min < \theta < \theta_\max) = \gamma, \; \gamma \rightarrow 1
$$

$theta_\min$ и $\theta_\max$ --- границы доверительного интервала, $\gamma$ --- доверительная вероятность. На практике её значение чаще всего принимается равным $0.95$.

**Алгоритм определения интервальной оценки** следующий:

1) Найсти статистику $\zeta(\theta)$, связанную с оцениваниемым параметром, закон распределения которой известен $f(\zeta)$.
2) Определить значения $\zeta_\min$ и $\zeta_\max$, в пределах которых статистика находится с вероятностью $\gamma$.
3) Зная связь $\zeta(\theta)$ перейти к границам $\theta_\min$ и $\theta_\max$.

Разберемся с этим на примере построения доверительного интервала для генерального среднего.

Первая задача --- найти статистику. Мы воспользуемся тем, что за нас поработали учёные-статистики и сказали, что вот такая вполне подойдёт:

$$
t = \frac{\bar x - \mu}{s}\sqrt{n-1},
$$

где $t$ --- значение статистики, $\bar x$ --- выборочное среднее, $\mu$ --- генеральное среднее, $s$ --- выборочное стандартное отклонение, $n$ --- объём выборки.

Известен ли закон её распредления? Да. Эта статистика подчинается $t$-распределению (распределению Стьюдента). Оно похоже на нормальное, но хвосты у него повыше:

<center>
<img src="img/student_pdf.jpg">
</center>

Теперь надо сформулировать вид интервальной оценки для генерального среднего. Путем арифметических преобразований формулы выше мы имеет следующее:

$$
\mu = \bar x - t \frac{s}{\sqrt{n-1}}
$$

Значит вид интервальной оценки будет таков:

$$
\mathrm{P}\Big( \bar x - t_\alpha \frac{s}{\sqrt{n-1}} < \mu < 
\bar x + t_\alpha \frac{s}{\sqrt{n-1}}\Big) = 1 - \alpha = \gamma
$$

Посмотрим на картинку:

<center>
<img src="img/mean_ci_graph.jpeg">
</center>

Видим на ней наш доверительный интвервал и значения $t_\alpha$ и $-t_\alpha$. Сама $\alpha$ обозначает вероятность выхода за границы доверительного интервала. Осталось всё это высчитать в числах, и получить границы доверительного интервала.

Хорошо, что весь этот ужас в R скрыт под капотом:

```{r, message=FALSE}
# mean_cl_normal(iq$IQ)
# mean_cl_boot(iq$IQ)
```




## Тестирование гипотез

```{r stats-testing-pkgs, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
theme_set(theme_bw())
library(latex2exp)
```

В ходе статистического анализа мы, главным образом, заняты тем, что тестируем статистические гипотезы. Ведь на какого рода вопросы мы отвечаем с помощью анализа?

- Различаются ли группы между собой?
- Значимо ли влияние какого-либо фактора? → Различаются ли группы между собой?
- Хороша ли та модель, которую мы построили? → Отличается ли она от нулевой модели?

И так далее. Так или иначе, всё сводится в тому, что мы ищем какие-то различия. Но силу того, что у нас неопределённость и вариация в данных, мы просто так «в лоб» сказать о различиях по оценкам параметров не можем. Приходится тестировать статистические гипотезы.

### Нулевая и альтернативная гипотезы {#stats-testing-hyotheses}

Еще раз тезисно [вспомним о гипотезах](#stats-hypotheses) в целом:

- **Гипотеза** ($H$) --- это предположение, которое подлежит проверке на основе результатов наблюдений.
- Гипотезы бывают:
    - **теоретические** --- про конструкты
    - **эмпирические** --- про переменные
    - **статистические** --- про параметры [генеральной совокупности] и данные

Статистические гипотезы бывают простыми и сложными:

- **Простая гипотеза** --- это такое предположение, которое включает в себя какое-либо однозначно определеяемое утверждение. Например, истинная величина параметра соответствует некоторому строго заданному значению: $H : \theta = \theta_0$. Другой вариант --- две генеральные совокупности имеют одно и то же значение одной и той же характеристики: $H : \theta_1 = \theta_2$.
- **Сложная гипотеза** предполагает множественность вариантов для параметра, которые укладываются в рамки проверяемого предположения. Например, $H : \theta > \theta_0$ или $H : \theta_1 \neq \theta_2$.

В рамках самого хода тестирования гипотез существует **проверяемая (нулевая) гипотеза** ($H_0$). Её обычно стараются предельно упростить, поэтому она формулируется как простая гипотеза. В противовес ей выдвигается **альтернативная гипотеза** ($H_1$), которая будет иметь вид сложной гипотезы.

Для проверки гипотезы необходимы две вещи:

- результаты наблюдений и
- критерий.

Результаты наблюдений, полученные на выборке, сами по себе, как правило, не используются. Однако на их основе рассчитываются выборочные статистики (показатели), которые непосредственно участвуют в проверке гипотезы.


### Подходы к тестированию статистических гипотез {#stats-testing-approaches}

#### Фреквентистский подход {#stats-testing-nhst}

#### Байесовский подход {#stats-testing-bayes}

### Возможные результаты проверки гипотез {#stats-testing-results}

В результате проверки статистических гипотез могут возникнуть четыре ситуации.

Мы изучаем в исследовании какую-либо закономерность, которая в реальном мире может существовать, а может и не существовать. В силу неопределённости и вариативности наших данных мы может либо обнаружить интересующую нас закономерность, либо не обнаружить.

В качестве нулевой гипотезы мы выдвигаем предположение о том, что закономерность отсутствует --- так мы упрощаем нашу нулевую гипотезу. Пусть $H_0$ обозначает, что предположение, которое мы проверяем справедливо, а $H_1$ --- не справедливо. На основании данных мы можем либо не отклонить наше предположение ($\hat H_0$), либо отклонить ($\hat H_1$).

Тогда имеем следующую ситуацию:

|            | $H_0$         | $H_1$          |
|:----------:|:-------------:|:--------------:|
| $\hat H_0$ | ✓             | Ошибка II рода |
| $\hat H_1$ | Ошибка I рода | ✓              |

- **Ошибка I рода** возникает, когда в генеральной совокупности _искомой закономерности нет_, но мы в силу случайных флуктуаций в данных _её нашли_.
- **Ошибка II рода** возникает, когда в генеральной совокупности _искомая закономерность есть_, но мы в силу каких-либо причин её _не нашли_.

Ошибки --- это нехорошо, они нас не устраивают. Надо каким-то образом их контролировать.

- **Ошибка I рода** контролируется достаточно просто. Так как мы _нашли_ закономерность, которую искали, мы можем посчитать вероятность, с которой потенциально ошиблись. А собственно контролировать ошибку мы будем с помощью **уровня значимости** $\alpha$, который _выбирается до начала процедуры тестирования гипотезы_. Он и задает вероятность, с который мы позволяем себе ошибиться — отклонить нулевую гипотезу, при условии, что она верна.
- **Ошибку II рода** контролировать сложнее, так как мы _не нашли_ закономерность, которую искали. Нам нужна какая-то метрика, которая позволит сказать, что мы сделали всё возможное для того, чтобы обнаружить искомую закономерность. Вероятность ошибки II рода обозначается $\beta$ --- тогда вероятность того, что мы не совершили ошибку II рода будет $1 - \beta$. Эта величина называется [**статистической мощностью**](#stats-testing-effect-size), и она связана с [_размером эффекта_](#stats-testing-effect-size) и _объемом выборки_. Статистическую мощность можно рассчитать как до проведения статистического анализа  для расчета требуемого объема выборки --- так и после --- для определения достигнутой статистической мощности.

Соберем все обозначения в единую табличку[^cond_prob]:

|            | $H_0$ | $H_1$|
|:----------:|:----------------------------:|:--------------------------:|
| $\hat H_0$ | $\mathrm P (\hat H_0 | H_0)$ | $\mathrm P (\hat H_0 | H_1) = \beta$ |
| $\hat H_1$ | $\mathrm P (\hat H_1 | H_0) = \alpha$ | $\mathrm P (\hat H_1 | H_1) = 1 - \beta$ |

[^cond_prob]: Здесь использовано обозначение условной вероятности $\mathrm P(A|B)$, то есть это вероятность того, что случилось событие $A$ при условии, что случилось событие $B$.

Уровень значимости $\alpha$ **выбирается близким к нулю** --- всем знакомо конвенциональное значение $0.05$. Вообще $\alpha$ можно выбрать сколь угодно малым, однако при выборе уровня значимости руководствуются принципом разумной достаточности, так как если устремить $\alpha$ к нулю, то устремиться к нулю и вероятность отклонения нулевой гипотезы.

<div class="advanced">
<details>
<summary>*Математические руны*</summary>
$$
\mathrm P (\hat H_1) = \mathrm P (\hat H_1 | H_0) \cdot \mathrm P (H_0) = \alpha \cdot \mathrm P(H_0)
$$
</details>
</div>


Достаточной статистической мощностью считается $0.8$. Аналогично, устремляя мощность к единице ($(1 - \beta) \rightarrow 1 \Rightarrow \beta \rightarrow 0$), мы устремляем вероятность не отклонения нулевой гипотезы к нулю:

<div class="advanced">
<details>
<summary>*Ещё математические руны*</summary>
$$
\mathrm P (\hat H_0) = \mathrm P (\hat H_0 | H_1) \cdot \mathrm P (H_1) = \beta \cdot \mathrm P (H_1)
$$
</details>
</div>


Необходимо также помнить, что ошибки первого и второго рода связаны между собой так, что

$$
\alpha \rightarrow 0 \Rightarrow \beta \rightarrow 1
$$


<div class="advanced">
<details>
<summary>*Опять математические руны*</summary>
$$
\beta \cdot \mathrm P (H_1) = \mathrm P (\hat H_0) = \mathrm P (\hat H_0 | H_0) \cdot \mathrm P (H_0) \Rightarrow \beta = \frac{1}{\mathrm P (H_1)} \cdot \mathrm P (H_0) \cdot \mathrm P(\hat H_0 | H_0) \\
\beta = \frac{1}{\mathrm P (H_1)} \cdot \big (1 - \mathrm P (H_1 | H_0)\big) = \frac{1}{\mathrm P (H_1)} \cdot \mathrm P (H_0) \cdot (1 - \alpha)
$$
</details>
</div>


#### Асимметрия статистического вывода {#stats-testing-asymmetry}

Выше мы сказали, что для проверки гипотезы нужны две вещи:

* результаты наблюдений и
* критерий.

С результатами наблюдений более-менее очевидно.

**Критерий** --- это правило, согласно которому гипотезу либо принимают, либо отклоняют. Однако перед тем как проверять гипотезу, её так-то нужно сформулировать, и сделать это правильно, поскольку от формулировки гипотезы зависит интерпретация результатов проверки и дальнейшее использование полученной информации.

Используемая статистика сама по себе является [непрерывной] случайной величиной, а значит может быть построено её распределение. Критерий будет разделять это распределение на непересекающиеся области. В результате чего возникает **критическая область** --- область отклонения гипотезы. Дополнением к ней является область неотклонения гипотезы.

Критическая область может быть односторонней (при $H_1:\theta > \theta_0$ или $H_1: \theta < \theta_0$) и двусторонней (при $H_1:\theta \neq \theta_0$). «Размер» критической области определяется **уровнем значимости**.


Статистический вывод — заключение о том, получили ли мы подтверждение альтернативной гипотезы — по структуре представляет собой *импликацию*. Если вам не знаком этот термин из логики, то вот:

* Если значение нашей статистики, которое мы рассчитали на выборке, *попало в критическую область*, то мы говорим о том, что *нулевая гипотеза отклоняется*.
* Если значение нашей статистики, которое мы рассчитали на выборке, *не попало в критическую область*, то мы *не получаем оснований для того, чтобы отклонить нулевую гипотезу*. Однако *мы также не получаем оснований, чтобы её «принять»*. Мы остаёмся в некотором неведении: мы не нашли различий, а есть они там или нет --- хто ж их знает… Итого, мы не можем сделать никакого вывода.

В этом и заключается асимметрия статистического вывода. Как раз для того, чтобы с ней как-то жить, мы работаем со статистической мощностью.

***

Посмотреть, как все эти штуки друг с другом соотносятся можно [тут](https://rpsychologist.com/d3/nhst/).

***


#### Связь ошибки первого и второго рода {#stats-testing-errors-connection}


### Агоритм тестирования статистических гипотез {#stats-testing-algorithm}

Для тестирования гипотез есть два сценария: *первый* и *тот, которым мы будем пользоваться*. Первый вариант чуть более классический, второй --- более гибкий.

**Сценарий номер раз**

1. Формулировка гипотезы
2. Выбор статистического критерия
3. Выбор уровня значимости $\alpha$
4. Построение закона распредления статистики критерия при условии, что нулевая гипотеза верна
5. Определение границ критической области
6. Расчёт выборочной статистики
7. Определение, попадает ли наблюдемое значение статистики в критическую область и вынесение решения

**Сценарий номер два**

1. Формулировка гипотезы
2. Выбор статистического критерия
3. Выбор уровня значимости $\alpha$
4. Построение закона распредлеения статистики критерия при условии, что нулевая гипотеза верна
5. Расчёт выборочной статистики
6. Расчёт достигнутого уровня значимости *p-value*
7. Сопоставление $\alpha$ и *p-value* и вынесение решения


Почему второй вариант более гибкий? Представим, что мы захотели понизить уровень значимости с $0.05$ до $0.01$ --- такие уровни значимости всречаются, например, в медицине. Если мы идем по первому сценарию, то нам надо заново пересчитать критические значения и вновь проанализировать, попадает ли наблюдаемое значение в критическую область. Если мы адепты второго сценария, то нам надо только выполнить одно новое сравнение нашего *p-value* с новым уровнем значимости.


### Размер эффекта {#stats-testing-effect-size}


### Статистическая мощность {#stats-testing-power}

::: {.callout-note title="Статистическая мощность Post hoc"}
НАПИСАТЬ

есть ли смысл рассчитывать статистическую мощность пост хок?

кажется, нет, так как эффект уже нашли
:::


### Ложноположительный вывод {#stats-testing-false-positive}

#### Проблема множественных сравнений {#stats-testing-multiple-comparisons}

Итак, мы сравниваем попарно все группы наблюдений между собой. В каждом сравнении мы фиксируем вероятность ошибки первого рода с помощью уровня значимости на уровне $0.05$. А какова будет вероятность ошибки, если мы проводим несколько сравнений?

Считаем, что наши сравнения независимы, поэтому вероятности будут перемножаться1. Если верояность ошибиться в одном сравнении равна $\alpha$, то вероятность сделать правильный вывод --- $1 - \alpha$. Тогда вероятность сделать правильный вывод в $m$ сравнениях --- $(1 - \alpha)^m$. Отсюда мы можем вывести вероятность ошибиться хотя бы в одном сравнении:

$$
\prob^′ = 1 - (1 - \alpha)^m
$$
 

Пусть у нас есть три группы, которые нам надо сравнить друг с другом — получается необходимо провести три сравнения. Итого вероятность ошибиться получается:

$$
\prob^′ = 1 - (1 - 0.05)^3 \approx 0.143
$$

Значительно больше, чем $0.05$, что нехорошо. И дальше только хуже. Поэтому нам надо либо корректировать уровень значимости, либо использовать мощные методы типа дисперсионного анализа.

```{r alpha-raise, echo=FALSE}
#| label: alpha-raise
#| fig-cap: "Рост вероятности ошибки первого рода при увеличении числа попарных сравнений"
 
alpha_multiple_comp <- function(n, alpha = .05) {1 - (1 - alpha) ^ n}

tibble(n = 1:10,
       alpha05 = alpha_multiple_comp(n),
       alpha001 = alpha_multiple_comp(n, alpha = .001)) |>
  pivot_longer(cols = -n, names_to = "alpha", values_to = "value") |> 
  ggplot(aes(x = n, y = value, color = alpha)) +
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks = 1:10) +
  scale_color_discrete(labels = c(alpha05 = "0.05", alpha001 = "0.001")) +
  labs(x = "Number of comparisons",
       y = TeX("$$\\alpha$$"),
       color = "Level of Significance") +
  theme(legend.position = "bottom")
```

##### Корректировка уровня значимости {#stats-testing-correction}

Корректировать уровень значимости можно по-разному. Например, можно разделить $\alpha$ на количество попарных сравнений — такой способ называется поправкой Бонферрони (Bonferroni):

$$
\alpha’ = \frac{\alpha}{n},
$$

где $n$ --- число попарных сравнений.

Поправка Бонферрони считается самой консервативной поправкой — она достаточно сильно уменьшает уровень значимости, и мы можем не поймать искомую закономерность, то есть совершить ошибку второго рода2. Поэтому придумали более либеральные поправки, например, поправку Холма (Холма–Бонферрони, Holm) или поправку Тьюки (Tukey’s HSD test). Можно посмотреть на их формулы, но в целом, не обяз, потому что их все равно никто не знает, а в статистических пакетах мы либо допишем аргумент в функцию, либо нужную галку поставим.

На практике в силу того, что в статистических пакетах мы работаем с p-value, корректируется именно его значение.

По достаточно незамысловатой логике
Здесь: вариант для поправки Бонферрони.

$$
p < \frac{\alpha}{n} \Rightarrow np < \alpha
$$
 
Таким образом, мы просто сравниваем уже скорретированное p-value, которое нам считает программа, с тем же самым $\alpha = 0.05$. Жизнь становится значительно проще и приятнее.



#### Проблема количества статистических тестов {#stats-testing-multiple-testing}


