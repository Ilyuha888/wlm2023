# L5 // Введение в статистику. Случайный эксперимент и случайные величины

{{< include ../book/_symbols.qmd >}}

```{r opts, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, message = FALSE, warning = FALSE)
```

```{r pkgs}
library(tidyverse)
theme_set(theme_bw())
library(ggforce)
```

## Введение в математическую статистику

**Статистика** --- это междисциплинарная область знаний, а также практической деятельности, изучающая массовые явления, а также прицнипи и методы работы с данными, характеризующими эти явления.

Массовые явления затрагивают огромные массы людей. Огромность масс, конечно, различна. Скажем, базовые перцептивные закономерности, связанные с тем, как устроена зрительная система, охватывают *всех людей*. Уровень удовлетворенности жизнью россиян охватывает только *население России*. Городские блага москвичей --- только для *жителей Москвы*. Учебная мотивация студентов департамента психологии НИУ ВШЭ --- это только про *людей с психологических бакалариата и магистратур НИУ ВШЭ*.

### Генеральная совокупность

**Генеральная совокупность (population)** --- множество всех [существующих] исследуемых объектов и сведений о них.

**Объем генеральной совокупности** ($N$) --- число единиц, образующих генеральную совокупность.

Генеральная совокупность недоступна для изучения в полном объеме, так как $N$ имеет порядок сотен, тысяч или даже миллионов... Поэтому в рамках исследований мы всегда работаем с выборкой.

### Выборка

**Выборка, или выборочная совокупность (sample)** --- множество объектов генеральной совокупности, объемом $n$ ($n \ll N$).

#### Репрезентативность выборки

Статистика даёт нам теоретический и математический аппарат, который позволяет делать выводы о генеральной совокупности по выборке. Однако если мы криво собрали данные, то никакая математика нас не спасет от некорректных выводов.

> Garbage in, garbage out.

**Репрезентативность** --- степень соответствия характеристик выборки характеристикам генеральной совокупности.

Например, мы хотим исследовать связь учебной мотивации и академической успеваемости бакалавров психологии. Если мы соберем данные только со своих однокурсников, будет нехорошо, так как в нашу выборку не попали (1) другие курсы психологического бакалавриата нашего вуза, (2) бакалавры-психологи других вузов Москвы и (3) бакалавры-психологи вузов других городов России.

*И так работает всегда.*

Ну, почти. Есть соблазн проводить исследования на студентах-психологах, потому что они достаточно близко и их можно загнать на эксперименты за баллы. Более-менее сносно это может работать на каких-то базовых когнитивных феноменах из восприятия и памяти. Обычно у нас нет оснований предполагать, что восприятие и память работают по-разному у людей разного возраста и разных социальных страт. Но вот уже с мышлением возникают проблемы.

**Почему выборка должна быть репрезентативной?**

Потому что если мы делаем нормально, то хотим обобщать результаты нашего исследования, полученные на выборке, на генеральную совокупность. Если выборка нерепрезентативна, то мы не можем этого сделать. Зачем в таком случае проводить исследование --- решительно неясно.

#### Как набрать репрезентативную выборку

0. Осознать, **кто наша генеральная совокупность**, так как для каждой генеральной совокупности репрезентативная выборка будет своя.
1. Понять, **есть ли какая-то группировка, _важная для нашего исследования_, в нашей генеральной совокупности** --- социальная страта, специальность образования, сфера работы, пол / гендер, возрастные группы, регион проживания, семейное положение, что-либо ещё.
2. Рассчитать **достаточный объём выборки**. Это не самая простая задача и о ней мы будем говорить отдельно. Пока отметим в назывном порядке, что на объем выборки будут влиять дизайн исследования, изменчивость признака, уровень значимости и размер эффекта [что бы это ни значило].
3. Обеспечить **случайное попадание респондентов в выборку**.

Здесь надо остановиться подробнее. Если у нас есть ресурсы набрать много человеков в выборку (скажем, раза в 2–3 больше, чем достаточный объем выборки), то можно просто случайным образом откуда-то доставать людей --- и всё будет хорошо. Закон больших чисел и центральная предельная теорема говорят, что наша выборка будет репрезентативной. Пока примем это как данность, позже поговорим об это подробнее.

<details>
<summary>Для интересующихся</summary>

**Закон больших чисел**

> С увеличением числа случайных величин их среднее арифметическое стремится к среднему арифметическому математических ожиданий и перестает быть случайным. Общий смысл закона больших чисел — совместное действие большого числа случайных факторов приводит к результату, почти не зависящему от случая.

Таким образом, закон больших чисел гарантирует устойчивость для средних значений некоторых случайных событий при достаточно длинной серии экспериментов.

**Центральная предельная теорема**

> Распределение случайной величины, которая получена в результате сложения большого числа независимых случайных величин (ни одно из которых не доминирует, не вносит в сумму определяющего вклада и имеет дисперсию значительно меньше по сравнению с дисперсией суммы) имеет распределение, близкое к нормальному.

Из ЦПТ следует, что ошибки выборки также подчиняются нормальному распределению.

***

</details>

Если мы всё же не можем набрать много человеков, то надо набрать выборку достаточного объема и проверить репрезентативна ли она --- отражает ли выборка те группировки объектов, которые есть в генеральной совокупности.

Идеальная выборка --- это когда каждый человек имеет равную вероятность попасть в число респонтентов / испытуемых. Полностью случайный отбор трудно достижим --- это очень дорого и логистически сложно --- но к нему нужно стремиться. Сам метод сбора данных может деформировать выборку (например, онлайн опросы отсекают пенсионеров), поэтому думать о сборе данных необходимо уже на этапе планирования исследования.


#### Способы формирования репрезентативной выборки

> Здесь представлены три классических способа формирования выборки. В конкретном исследовании мы можем использовать и какие-либо другие способы формирования выборки, однако нам нужно будет обосновать, почему с нашем случае тот или иной способ позволяет собрать репрезентативную выборку.

##### Простая случайная выборка (simple random sample)

- Элементы генеральной совокупности случайным образом попадают в выборку
- С увеличением объема простая случайная выборка будет все больше напоминать генеральную совокупность по своим характеристикам.

Представим, что на этой картинке изображена вся генеральная совокупность:

```{r simple-random-pop}
tibble(x = runif(1500), 
       y = runif(1500), 
       smpl = sample(c(TRUE, FALSE), 1500, 
                     replace = TRUE, prob = c(.2, .8))) -> simple_random_pop

simple_random_pop %>% 
  ggplot(aes(x, y)) +
  geom_point() +
  guides(x = "none", y = "none") +
  labs(x = "", y = "")
```

Если мы наберем простую случайную выборку из этой генеральной совокупности, она будет выглядеть так (черные точки):

```{r simple-random-sample}
simple_random_pop %>% 
  ggplot(aes(x, y, color = smpl)) +
  geom_point() +
  guides(x = "none", y = "none", color = "none") +
  labs(x = "", y = "") +
  scale_color_manual(values = c(`TRUE` = "black", `FALSE` = "gray70"))
```

Как можно заметить, в выборку попали объекты из всех частей нашей генеральной совокупности — говорит о том, что выборка репрезентативна.


##### Стратифицированная выборка (stratified sample)

* Генеральная совокупность разбивается на несколько обособленных различных по своей природе групп (страт). Например, по полу или уровню образования
* Из каждой группы случайным образом выбираются несколько объектов, которые попадают в выборку.

Пусть в нашей генеральной совокупности есть пять страт:

```{r strat-pop}
tibble(x = runif(1500), 
       y = runif(1500), 
       strat = sample(c("A", "B", "C", "D"), 1500, 
                      replace = TRUE, prob = c(.15, .2, .4, .25)),
       smpl = sample(c(TRUE, FALSE), 1500, 
                     replace = TRUE, prob = c(.1, .9))) -> strat_pop

strat_pop %>% 
  ggplot(aes(x, y, color = strat)) +
  geom_point() +
  guides(x = "none", y = "none") +
  labs(x = "", y = "", color = "Stratum") +
  theme(legend.position = "bottom")
```

Тогда мы можем разделить её на пять «генеральных совокупностей» соответственно:

```{r strat-sample}
strat_pop %>% 
  ggplot(aes(x, y, color = strat)) +
  geom_point() +
  guides(x = "none", y = "none", color = "none") +
  facet_wrap(~ strat) +
  labs(x = "", y = "", color = "Stratum") +
  theme(legend.position = "bottom")
```

Из каждой такой «генеральной совокупности» будем извлекать случайную выборку:

```{r strat-pop-strata}
strat_pop %>% 
  ggplot(aes(x, y, color = strat, alpha = smpl)) +
  geom_point() +
  guides(x = "none", y = "none", color = "none", alpha = "none") +
  facet_wrap(~ strat) +
  labs(x = "", y = "", color = "Stratum") +
  theme(legend.position = "bottom")
```


##### Групповая выборка (cluster sample)

- Генеральная совокупность разбивается на несколько обособленных, но одинаковых групп (кластеров). Например, население города группируется по району проживания
- Выбираются случайным образом несколько групп
- Из каждой группы случайным образом выбираются несколько объектов, которые попадают в выборку.

Пусть мы разделили нашу генеральную совокупность на 8 кластеров:

```{r cluster-pop}
tibble(x = rnorm(100, 0, .3),
       y = rnorm(100, 0, .3), 
       cluster = TRUE,
       smpl = sample(c(TRUE, FALSE), 100, replace = TRUE, prob = c(.1, .9))) %>% 
  bind_rows(
    tibble(
      x = rnorm(100, 2, .5),
      y = rnorm(100, 2, .5),
      cluster = FALSE, 
      smpl = FALSE
    )
  ) %>% 
  bind_rows(
    tibble(
      x = rnorm(100, -2, .5),
       y = rnorm(100, -2, .5),
      cluster = FALSE,
      smpl = FALSE
    )
  ) %>% 
  bind_rows(
    tibble(
      x = rnorm(100, 1.5, .3),
       y = rnorm(100, 5, .3),
      cluster = TRUE,
      smpl = sample(c(TRUE, FALSE), 100, replace = TRUE, prob = c(.1, .9))
    )
  ) %>% 
  bind_rows(
    tibble(
      x = rnorm(100, 3, .5),
       y = rnorm(100, -2, .5),
      cluster = FALSE,
      smpl = FALSE
    )
  ) %>% 
  bind_rows(
    tibble(
      x = rnorm(100, 1, .5),
       y = rnorm(100, -4, .5),
      cluster = TRUE,
      smpl = sample(c(TRUE, FALSE), 100, replace = TRUE, prob = c(.1, .9))
    )
  ) %>% 
  bind_rows(
    tibble(
      x = rnorm(100, 5, .5),
       y = rnorm(100, 2, .5),
      cluster = TRUE,
      smpl = sample(c(TRUE, FALSE), 100, replace = TRUE, prob = c(.2, .8))
    )
  ) %>% 
  bind_rows(
    tibble(
      x = rnorm(100, -3, .5),
       y = rnorm(100, 4, .5),
      cluster = FALSE,
      smpl = FALSE
    )
  ) -> cluster_pop

cluster_pop %>% 
  ggplot(aes(x, y)) +
  geom_point() +
  guides(x = "none", y = "none", color = "none", alpha = "none") +
  labs(x = "", y = "")
```

Кластеры у нас примерно одинаковые по характеристикам между собой — по крайне мере, мы так предполагаем. Выберем случайно четыре кластера, которые примут участие в исследовании:

```{r cluster-clusters}
cluster_pop %>% 
  ggplot(aes(x, y, color = cluster)) +
  geom_point() +
  guides(x = "none", y = "none", color = "none", alpha = "none") +
  labs(x = "", y = "") +
  scale_color_manual(values = c(`TRUE` = "black", `FALSE` = "gray70"))
```

Теперь из этих кластеров наберем выборку (допустим, по 20 наблюдений из кластера) случайным образом (объекты, попавшие в итоговую выборку отмечены черным контуром, не попавшие — серым):

```{r cluster-sample}
cluster_pop %>% 
  ggplot(aes(x, y, color = cluster, alpha = smpl)) +
  geom_point() +
  guides(x = "none", y = "none", color = "none", alpha = "none") +
  labs(x = "", y = "") +
  scale_color_manual(values = c(`TRUE` = "black", `FALSE` = "gray70"))
```

Такой подход к формированию выборки позволяет экономить драгоценные ресурсы при проведении исследования.

> Подробнее про разные способы сбора выборки можно почитать [тут](https://www.scribbr.com/methodology/sampling-methods/).

### Характетистики объектов выборки и генеральной совокупности

Объекты генеральной совокупности обладают определенными **признаками**, которые мы и хотели бы изучать. Признаки _количественно выражены_ в определенных **показателях**. Например,

|Признак|Показатель|
|:---|:---|
|Рабочая память|Объем рабочей памяти|
|Нейротизм|Уровень нейротизма по BFI|
|Доход|Совокупный годовой доход после уплаты налогов|
|Когнитивная нагрузка|Уровень когнитивной нагрузки по ЭЭГ-коррелятам|
|Доверие к ИИ|Уровень доверия к ИИ по опроснику TAIA|
|Индивидуализм/коллективизм|Индекс индивидуализма/коллективизма по модели Хофстеде|

Признаки могут быть очень разными и измеряться могут с помощью разных показателей.

Независимо от того, как измеряется признак, генеральная совокупность характеризуется _параметром_.

**Параметр** ($\theta$) --- относительно постоянная [от одной совокупности к другой] величина, харакретизующая генеральную совокупность по некоторому показателю.

Ну, то есть в принципе существует _средний уровень нейротизма по BFI студента-психолога_ или _индекс индивидуализма/коллективизма для конкретной культуры_. Проблема в том, что **величина параметра, который мы изучаем, неизвестна**. И никогда не будет известна.

Но почему?

- Мы не можем изучать всю генеральную совокупность --- слишком много объектов
- Наши измерения всегда содержат ошибку --- мы даже длину линейкой точно не можем измерить, что уж о психологических измерениях говорить

Поэтому величину параметра мы можем только предсказать с определённой статистической точностью. Измеряя что-либо на выборке, мы получаем **выборочную характеристику, или оценку** ($\hat \theta$) --- эмпирический (измеримый) аналог параметра.



### Характеристики статистических данных

Итак, теперь задумаемся о том, что мы собираем на выборке некоторые данные. К каким их особенностям приведут все моменты, описанные выше?

* Мы не можем работать с генеральной совокупностью, поэтому набираем выборку --- выборки между собой имеют право различаться
* Каждый респондент или испытуемый обладает своими особенностями --- мы не знаем, что мы получим в результате конкретного измерения на конкретном изучаемом объекте[^obj_subj]
* Любое наше измерение содержит ошибку --- ни один измерительный инструмент не является совершенным

[^obj_subj]: Возможно, не очень хорошо называть человека «объектом», однако так как мы сейчас в методологии количественных исследований, будем оперировать именно этим термином.

Всё это приводит нас к двум ключевым характеристикам статистически данных --- _неопределенности_ и _вариативности_.

* **Неопределённость** нам говорит о том, что мы не знаем, что именно мы получим в результате наших измерений для конкретной выборки.
    * Отсюда чуть позже возникнут _случайные величины_.
* **Вариативность** означает, что наши данные будут различатся от выборки к выборке и от респондента к респонденту
    * Отсюда возникнут _статистические критерии_, в которых эта характеристика данных будет учтена в ходе тестирования гипотез.



### Зачем нужна статистика?

Мы в какой-то малоприятной ситуации… Мы пытаемся измерить то, что в определенном смысле невозможно измерить, при этом достаточно точно, чтобы потом это можно было сравнивать или строить какие-то модели. Задача выглядит заведомо провальной…

Однако именно в этот момент на помощь нам приходит статистика. Не в гордом одиночестве, конечно. Она проводит с собой теорию измерений, психометрику, теорию обнаружения сигнала и др. Всё это работает в нашей психологической науке в комлексе.

Статистика даёт нам теоретический и математический инструментарий, чтобы мы могли делать какие-либо выводы по нашим собранным данным. К сожалению, как бы нам не хотелось, мы не можем делать выводы по сырым данным, потому что измерения по выборке не отражают вот прям ровно то, что есть в генеральной совокупности. Нам их надо определенным образом обсчитать, чтобы наши выводы были корректными. Этим и занимается статистика.

Возможно, это звучит достаточно абстрактно, но я хочу, чтобы на данном моменте вы поймали некоторое интуитивное понимание того, зачем нужна статистика. Далее это обрастёт содержанием и уложится, я надеюсь, в достаточно стройную систему.

**Итог --- статистика помогает нам делать выводы о нашей генеральной совокупности по выборке.**



## Случайный эксперимент

Отвлечемся немного на любимый объект статистиков --- игральный кубик.

<center>
<figure>
<img src="pics/kubik.jpg" style="width: 30%">
</figure>
</center>

* Бросание игрального кубика --- это *случайный эксперимент*.
* Выпавшее число --- это *случайная величина*.

Теперь более строго.

**Случайный эксперимент** --- это математическая модель некоторого реального эксперимента, результат которого невозможно точно предсказать.

Ключевой момент в случайном эксперименте --- это то, что его результат _невозможно точно предсказать_, то есть какой стороной упадёт кубик заранее неизвестно.

Это не соотносится с экспериментом как методом исследования. Эксперимент как метод исследования включает в себя сложную процедуту экспериментального воздействия, контроля систематических и несистематических смешений, манипуляции с независимыми переменными и фиксирование зависимых переменных и т.д. Случайный эксперимент же является частью эксперимента.

Посмотрим на примеры из психологического поля:

* ответ респондента на пункт (айтем) опросника --- это случайный эксперимент
    * неизвестно, какой балл выберет респондент
* клик на стимул на экране в эксперименте на зрительный поиск --- это случайный эксперимент
   * заранее неизвестно, когда точно испытуемый кликнет по стимулу
* запись ЭЭГ-активности в конкретный момент времени --- это случайный эксперимент
    * неизвестно, что мы зафиксируем в конкретный момент
* и т.д.

Отсюда мы делаем важный вывод: **любой акт измерения --- это [с точки зрения статистики] случайный эксперимент.**


### Модель случайного эксперимента

На модель случайного эксперимента накладывается ряд требований:

* адекватность описания реального эксперимента (в нашем случае, акта (момента) измерения)
* определение совокупности наблюдаемых результатов случайного эксперимента (при фиксированных начальных данных)
* принципиальная возможность осуществления эксперимента со случайным исходом сколько угодно большое количество раз (при фиксированных начальных данных)
* стохастическая устойчивость относительной частоты для любого наблюдаемого результата

Для того, чтобы это всё понять, нужно ввести некоторые концепты.


### Элементарные исходы и события

В случайном эксперименте возможны различные исходы, называемые **элементарными событиями** ($\omega_i$). Например, в случае упомянутого выше игрального кубика при его бросании возможны шесть элементарных событий (исходов):

* $\omega_1$ --- выпала грань с одной точкой
* $\omega_2$ --- выпала грань с двумя точками
* $\omega_3$ --- выпала грань с тремя точками
* $\omega_4$ --- выпала грань с четырьмя точками
* $\omega_5$ --- выпала грань с пятью точками
* $\omega_6$ --- выпала грань с шестью точками

Множество всех элементарных событий называется **пространством элементарных событий** ($\Omega$) случайного эксперимента.

В случае игрального кубика можно записать так:

$$
\Omega = \{\omega_1, \omega_2, \omega_3, \omega_4, \omega_5, \omega_6\}
$$

В общем случае, когда возможны $n$ случайный исходов случайного эксперимента, пространство элементарных событий будет выглядеть так:

$$
\Omega = \{\omega_1, \omega_2, \dots, \omega_{n-1}, \omega_n\}
$$

Аналогично, в случае, когда случайным экспериментом будет ответ респодента на пункт опросника по пятибалльной шкале Ликерта, пространство элементарных событий будет выглядеть так:

$$
\Omega = \{\omega_1, \omega_2, \omega_3, \omega_4, \omega_5\},
$$

где

* $\omega_1$ --- дан ответ «1» / «не согласен»
* $\omega_2$ --- дан ответ «2» / «скорее, не согласен»
* $\omega_3$ --- дан ответ «3» / «ни то, ни другое»
* $\omega_4$ --- дан ответ «4» / «скорее, согласен»
* $\omega_5$ --- дан ответ «5» / «согласен»

В пространстве элементарных событий определяются **случайные события** --- любое подмножество множества элементарных событий. Например, для игрального кубика

* случайное событие «выпало четное число очков» соответствует множеству $A_{\text{even}} = \{\omega_2, \omega_4, \omega_6\}$
* случайное событие «выпало нечетное число очков» соответствует множеству $A_{\text{odd}} = \{\omega_1, \omega_3, \omega_5\}$
* случайное событие «выпала грань с тремя точками» соответствует множеству $A_3 = \{\omega_3\}$
* случайное событие «не выпало ни одной грани» соответствует множеству $A_0 = \varnothing$ --- такое событие называется _невозможным_
* случайное событие «выпала любая грань» соответствует множеству $A_{\text{any}} = \Omega = \{\omega_1, \omega_2, \omega_3, \omega_4, \omega_5, \omega_6\}$ --- такое событие называется _достоверным_

Обратите внимание, что $A_{\text{even}} \subset \Omega$, $A_{\text{odd}} \subset \Omega$, $A_3 \subset \Omega$, $A_0 \subset \Omega$ и $A_{\text{any}} \subset \Omega$, что как раз и утверждает определение случайного события.

Всё множество случайных событий $A_i$ обозначается[^f_alg] $\mathcal A$.

[^f_alg]: Строго говоря, этим символом обозначается другая структура, называемая алгеброй (или сигма-алгеброй) событий, но нам будет достаточно этого более поверхностного понимания.

* Если пространство элементарных событий _конечно_ или _счетно_, то оно называется **дискретным**.
* Если пространство элементарных событий **недискретно** и элементарными исходами являются числа, то оно называется **непрерывным**.


### Вероятность

Окей, мы ввели пространство элементарных событий $\Omega$ и множество случайных событий $\mathcal A$. Однако этого оказывается недостаточно, чтобы работать с результатами случайного эксперимента. Так как исход случайного эксперимента невозможно точно предсказать, необходимо ввести меру, которая будет описывать возможность наступления того или иного события. Такая мера называется _вероятностью_.

**Вероятность** ($\prob$)--- относительная мера возможности наступления некоторого события в результате случайного эксперимента.

#### Классическая вероятность

Вернемся вновь к игральному кубику. Напомним себе, что мы определили пространство элементарных событий для случайного эксперимента «бросание игрального кубика» следующим образом:

$$
\Omega = \{\omega_1, \omega_2, \omega_3, \omega_4, \omega_5, \omega_6\}
$$

Зададим следующие ограничения, чтобы было удобнее работать с чиселками:

* вероятность _достоверного события_ должна равняться единице --- $\prob (\Omega) = 1$
* вероятность _невозможного события_ должна равняться нулю --- $\prob (A_0) = 0$

Предполагая, что кубик честный, то есть выпадение каждой грани _равновозможно_, можно определить вероятность выпадения каждой грани как 

$$
\prob (\omega_i) = \frac{1}{n},
$$

где $n$ --- количество всех возможных элементарных исходов случайного эксперимента. Получается, вероятность выпадения каждой грани --- $\frac{1}{6}$.

Аналогично можно определить вероятность любого случаного события $A_i$:

$$
\prob(A_i) = \frac{n_i}{n},
$$

где $n_i$ --- количество элементарных исходов, составляюших событие $A_i$, а $n$ --- количество всех возможных элементарных исходов случайного эксперимента. Получается, что вероятность выпадения четного числа очков $\prob (A_\text{even}) = \frac{3}{6} = \frac{1}{2}$, что достаточно логично.

Такой подход к вероятности называется **классической вероятностью**. Возвращаясь к требованиям модели случайного эксперимента, можно заключить, что такая модель (1) адекватно описывает реальный эксперимент, так как предсказанные вероятности согласуются с наблюдениями, (2) определяет совокупность наблюдаемых результатов случайного эксперимента ($\Omega$ и $\mathcal A$) и допускает принципиальную возможность осуществления случайного эксперимента сколь угодно большое количество раз.

Тройку $(\Omega, \mathcal A, \prob)$ называются **вероятностным пространством**.



#### Статистическая вероятность

С игральным кубиком классическая вероятность прекрасно работает. Однако задумается о следующем случае: какова вероятность встретить динозавра на улице?

Воспользуемся классическим подходом к вероятности. Зададим пространство элементарных событий, которое будет выглядеть так: $\Omega = \{\omega_1, \omega_2\}$, где $\omega_1$ --- встреча с динозавром случилась, а $\omega_2$ --- встреча с динозавром не случилась.

Получается, что вероятность встретить динозавра на улице равняется

$$
\prob (\omega_1) = \frac{1}{n} = \frac{1}{2}
$$

То есть, каждый второй день мы по пути на работу должны сталкиваться с каким-нибудь жителем триаса. Однако наши наблюдательные данные говорят, что этого не происходит. Получается, такая модель неадекватна реальности. В чем тут дело?

Классическая вероятность исходит из допущения _равновозможности наступления любого элементарного исхода_. Данное допущение в случае с динозавром нарушается. Чтобы корректно определить вероятность в данном случае, необходимо использовать _статистическую вероятность_.

Формально **статистическая вероятность** определяется как предел частоты наблюдений некоторого события при стремлении количества наблюдений к бесконечности [при их независимости (наблюдения не влияют друг на друга) и однороности (условия наблюдений одинаковы)]:

$$
\prob(A) = \lim_{N \rightarrow \infty} \frac{n}{N},
$$

где $N$ --- количество наблюдений, а $n$ --- количество наступлений события $A$.

То есть, чтобы оценить вероятность некотрого события, надо многократно повторить случайный эксперимент (провести большое количество наблюдений), посчитать, в скольки наблюдениях наступило интересующее нас событие, и поделить одно на другое. И чем больше наблюдений мы проведем, тем более точну оценку вероятности мы получим.

Такой подход дает адекватное описание происходящему в реальном мире --- вероятность встретить динозавра оказывается равной (крайне близкой) к нулю.

Отметим, что этот подход работает и с игральным кубиком: совершив много бросков кубика мы сможем выяснить, что вероятность выпадения каждой грани --- $\frac{1}{6}$, при условии, что кубик честный (что является допущением классической вероятности).

Мы будем опираться на статистический подход, поскольку в реальной исследовательской работе мы обычно имеем дело именно с _неравновозможными_ событиями.



#### Геометрическая вероятность

Посмотрим еще на один подход к определнию вероятности, которые нам пригодится ближе к концу курса. Поставим себе весьма абстрактную, но веселую задачу.

Возьмем квадрат, в который вписан круг:

```{r geomprob-square}
ggplot() +
  geom_rect(aes(xmin = -.5, xmax = .5, ymin = -.5, ymax = .5), color = "black", alpha = 0, linewidth = 1) +
  geom_circle(aes(x0 = 0, y0 = 0, r = .5)) +
  guides(x = "none", y = "none") +
  coord_fixed()
```

Будем бросать в этот квадрат точки случайным образом:

```{r geomprob-dots}
tibble(x = runif(100, -.5, .5),
       y = runif(100, -.5, .5)) %>% 
ggplot() +
  geom_rect(aes(xmin = -.5, xmax = .5, ymin = -.5, ymax = .5), color = "black", alpha = 0, linewidth = 1) +
  geom_circle(aes(x0 = 0, y0 = 0, r = .5)) +
  geom_point(aes(x, y)) +
  guides(x = "none", y = "none") +
  labs(x = "", y = "") +
  coord_fixed()
```

Вопрос: **какова вероятность, что случайно брошенная точка попадет в круг (событие $A$)?**

Мы можем воспользоваться статистическим подходом к вероятности, набросать побольше точек и посчитать, сколько из них попало в пределы круга:

```{r geomprob-incircle}
tibble(x = runif(1000, -.5, .5),
       y = runif(1000, -.5, .5),
       d = sqrt(x^2 + y^2),
       incirc = ifelse(d <= .5, TRUE, FALSE)) %>% 
ggplot() +
  geom_rect(aes(xmin = -.5, xmax = .5, ymin = -.5, ymax = .5), color = "black", alpha = 0, linewidth = 1) +
  geom_circle(aes(x0 = 0, y0 = 0, r = .5)) +
  geom_point(aes(x, y, color = incirc)) +
  guides(x = "none", y = "none", color = "none") +
  labs(x = "", y = "") +
  coord_fixed() +
  scale_color_manual(values = c(`TRUE` = "black", `FALSE` = "gray70"))
```

Из визуализации видно, что в конечном итоге при очень большом количестве бросаний точек они заполнят всю площадь квадрата, а значит, и всю площадь круга, поэтому вероятность попадания случайно прошенной точки в круг равняется отношению площади круга к площади квадрата, то есть:

$$
\prob (A) = \lim_{N \rightarrow \infty} \frac{n}{N} = \frac{S_\text{circle}}{S_\text{square}}
$$

Можно расписать точнее, если вспомнить геометрические формулы:

$$
\prob (A) = \frac{S_\text{circle}}{S_\text{square}} = \frac{\pi r^2}{a^2} = \frac{\pi \big(\frac{1}{2}a\big)^2}{a^2} = \frac{1}{4}\pi \approx 0.785
$$

Такое подход к определению вероятности называется **геометрической вероятностью**.

Отметим, что плоский случай можно обобщить и до объемного. В случае куба и шара вероятность будет равна

$$
\prob (A) = \frac{V_\text{circle}}{V_\text{square}} = \frac{\frac{4}{3}\pi r^3}{a^3} = \frac{1}{6} \pi \approx 0.523
$$



#### Условная вероятность

* Если у нас есть _несовместные_ события, то чтобы найти вероятность, что случится какое-либо из них, нужно _сложить_ их вероятности.
    * Так, если нам нужно выяснить, с какой вероятностью выпадет четыре или шесть очков на игральном кубике, нам надо сделать следующее: $\prob (A_{46}) = \prob (A_4) + \prob (A_6) = \prob (\omega_4) + \prob (\omega_6) = \frac{1}{6} + \frac{1}{6} = \frac{2}{6} = \frac{1}{3}$.
* Если у нас есть _независимые_ события, то чтобы найти вероятность, что случатся оба события сразу, нужно _перемножить_ их вероятности.
    * Так, если нам нужно выяснить, с какой вероятность на двух кубиках, бросаемых независимо, выпадет по шесть очков одновременно, нам надо сделать следующее: $\prob (A_{6,6}) = \prob (A^{(1)}_6) \cdot \prob (A^{(2)}_6) = \prob (\omega_6)^2 = \big(\frac{1}{6}\big)^2 = \frac{1}{36}$

**Но что делать, если нам нужно вычислить более сложную вероятность?**





















## Случайные величины

Когда мы первый раз обратились к игральному кубику,мы сказали, что бросание игрального кубика --- это *случайный эксперимент*, а выпавшее число --- это *случайная величина*. Со случайным экспериментом разобрались, приступим к случайным величинам.

**Случайная величина** --- это некоторая переменная, значения которой представляют собой численные исходы некоторого случайного эксперимента.

В частности, исход бросания кубика --- выпавшее число, исход фиксации времени реакции в эксперименте --- количество миллисекунд (число), исход измерения псиометрического конструкта --- суммарный балл по опроснику (число) и т.д.

Сами исходы случайного эксперимента числами быть в общем случае не обязаны, поэтому формально случайную величину $\xi$ определяют как функцию $y = \xi(\omega)$, или $\xi: \Omega \rightarrow \setR$, на вероятностном пространстве $(\Omega, \mathcal A, \prob)$, которая сопоставляет исходам случайного эксперимента некоторые числа.

Поскольку случайная величина это численное выражения исходов случайного эксперимента, а сами исходы осуществляются с определенными вероятностями, чтобы мочь работать со случайной величиной, необходимо _задать_ эту самую случайную величину, то есть _описать её вероятностные свойства_. Эти мы далее и займемся.

В зависимости от того, какое пространство элементарных событий было в случайном эксперименте --- дискретное или непрерывное --- случайные величины также могут быть дискретными или непрерывными.

### Дискретные случайные величины

Случайная величина является **дискретной**, если множество её значений конечно или счётно.

Функция вероятности

Функция распределения


### Непрерывные случайные величины

Случайная величина является **непрерывной**, если множество её значений обладает мощностью континуума.

Функция плотности вероятности

Функция распределения


### Характеристики распределения случайной величины

Математические ожидание

Дисперсия

Коэффициент асимметрии

Коэффициент эксцесса


### Некоторые распределения случайных величин

#### Равномерное распределение

#### Биномиальное распределение

#### Распределение Пуассона


#### Нормальное распределение


